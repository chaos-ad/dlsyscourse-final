{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Final Project\n",
    "\n",
    "In this final project I will implement DLRM model (https://arxiv.org/abs/1906.00091) and training it on the Criteo 1TB Click Logs Dataset (https://labs.criteo.com/2013/12/download-terabyte-click-logs/).\n",
    "\n",
    "As a contribution to the needle framework, I will be implementing (hopefully in a reusable manner) the following building blocks:\n",
    "\n",
    "- Binary Cross-Entropoy loss\n",
    "- hashing trick that would optimize memory footprint of the `Embedding` layer\n",
    "- data parallel distributed training using ray.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to set up the assignment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/\n",
    "# !mkdir -p 10714\n",
    "# %cd /content/drive/MyDrive/10714\n",
    "# !git clone http://github.com/chaos-ad/dlsyscourse-final.git\n",
    "# %cd /content/drive/MyDrive/10714/final\n",
    "\n",
    "# !pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
    "# !pip3 install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found pybind11: /home/ec2-user/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/pybind11/include (found version \"2.10.3\")\n",
      "-- Found cuda, building cuda backend\n",
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build\n",
      "make[1]: Entering directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "make[2]: Entering directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "make[3]: Entering directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "make[3]: Leaving directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "[ 50%] Built target ndarray_backend_cpu\n",
      "make[3]: Entering directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "make[3]: Leaving directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "make[3]: Entering directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "[ 75%] \u001b[32m\u001b[1mLinking CXX shared module /home/ec2-user/SageMaker/code/dlsyscourse-homework/final/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "[100%] Built target ndarray_backend_cuda\n",
      "make[2]: Leaving directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n",
      "make[1]: Leaving directory `/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/build'\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "_ = dotenv.load_dotenv(dotenv_path=\"../conf/dev.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apps.etl\n",
    "import apps.utils.aws\n",
    "import apps.utils.common\n",
    "\n",
    "## Hot code reloading, useful during dev:\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport apps.etl\n",
    "%aimport apps.utils.common\n",
    "%aimport apps.utils.aws.s3\n",
    "%aimport apps.utils.aws.athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"notebooks.final\")\n",
    "apps.utils.common.setup_logging(config_file=\"../conf/logging.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download criteo 1TB dataset into S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run me once to download data to S3 (bucket & prefix are controlled via conf/dev.env, and postfix is an argument defaulting to \"criteo/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps.etl.import_criteo_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into parquet format, so that column-wise operations will be much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps.etl.init_parquet_athena_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apps.etl.parse_criteo_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parts of the ETL are omitted here due to lack of time. But essentially for each feature we build a lookup dictionary sorted by frequency using Athena query. Next, we join it back to the sparse features, and use their indices in a dict instead (similarly to what we have done for PTB in HW4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-10 02:06:58,911 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp90netoa8\n",
      "2023-01-10 02:06:58,912 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp90netoa8/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import tests.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.debug.run_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-10 02:07:31,188 - tests.debug - DEBUG - TRAIN[epoch_id=1] on batch_id=1 of size 16384...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "std::bad_alloc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/final.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/final.ipynb#ch0000021vscode-remote?line=0'>1</a>\u001b[0m tests\u001b[39m.\u001b[39;49mdebug\u001b[39m.\u001b[39;49mrun_needle()\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/tests/debug.py:311\u001b[0m, in \u001b[0;36mrun_needle\u001b[0;34m(embedding_dim, num_embeddings_per_feature, over_arch_layer_sizes, dense_arch_layer_sizes, epochs, batch_size, learning_rate, weight_decay, with_pbar)\u001b[0m\n\u001b[1;32m    308\u001b[0m optimizer \u001b[39m=\u001b[39m ndl\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m    310\u001b[0m \u001b[39mfor\u001b[39;00m epoch_id \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     needle_train(model, loss_fn, optimizer, train_dataset, epoch_id\u001b[39m=\u001b[39;49mepoch_id, with_pbar\u001b[39m=\u001b[39;49mwith_pbar)\n\u001b[1;32m    312\u001b[0m     \u001b[39m# needle_eval(model, loss_fn, eval_dataset, epoch_id=epoch_id, with_pbar=with_pbar)\u001b[39;00m\n\u001b[1;32m    313\u001b[0m needle_eval(model, loss_fn, test_dataset, epoch_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, with_pbar\u001b[39m=\u001b[39mwith_pbar)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/tests/debug.py:205\u001b[0m, in \u001b[0;36mneedle_train\u001b[0;34m(model, loss_fn, optimizer, dataset, epoch_id, with_pbar)\u001b[0m\n\u001b[1;32m    201\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTRAIN[\u001b[39m\u001b[39m{\u001b[39;00mepoch_id\u001b[39m=}\u001b[39;00m\u001b[39m] on \u001b[39m\u001b[39m{\u001b[39;00mbatch_id\u001b[39m=}\u001b[39;00m\u001b[39m of size \u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m optimizer\u001b[39m.\u001b[39mreset_grad()\n\u001b[0;32m--> 205\u001b[0m Y_logits \u001b[39m=\u001b[39m model(X_dense, X_sparse)\n\u001b[1;32m    206\u001b[0m Y_logits \u001b[39m=\u001b[39m Y_logits\u001b[39m.\u001b[39mreshape((Y_logits\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],))\n\u001b[1;32m    207\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(Y_logits, Y_true)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/nn.py:76\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/apps/models.py:107\u001b[0m, in \u001b[0;36mDLRM.forward\u001b[0;34m(self, input_dense, input_sparse)\u001b[0m\n\u001b[1;32m    105\u001b[0m dense_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense_submodel(input_dense)\n\u001b[1;32m    106\u001b[0m sparse_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_submodel(input_sparse)\n\u001b[0;32m--> 107\u001b[0m cross_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_submodel(dense_embeddings, sparse_embeddings)\n\u001b[1;32m    108\u001b[0m \u001b[39m# logits = self.linear_layer(dense_embeddings)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m cross_features\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/nn.py:76\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/apps/models.py:56\u001b[0m, in \u001b[0;36mDLRMCrossPart.forward\u001b[0;34m(self, input_dense, input_sparse)\u001b[0m\n\u001b[1;32m     54\u001b[0m input_concat_rhs \u001b[39m=\u001b[39m ndl\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mtranspose(input_concat_lhs, axes\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m     55\u001b[0m \u001b[39m# FIXME: this should be analogous to torch.bmm, multiplying B times (D,F)*(F,D) instead of doing (B*D,F)*(F,B*D)\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m interactions \u001b[39m=\u001b[39m input_concat_lhs \u001b[39m@\u001b[39;49m input_concat_rhs \n\u001b[1;32m     57\u001b[0m interactions \u001b[39m=\u001b[39m ndl\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape(interactions, (input_concat\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], input_concat\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[1;32m     59\u001b[0m \u001b[39m# dense/sparse + sparse/sparse interaction\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m# size B X (F + F choose 2)\u001b[39;00m\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:343\u001b[0m, in \u001b[0;36mTensor.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__matmul__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 343\u001b[0m     \u001b[39mreturn\u001b[39;00m needle\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mMatMul()(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:73\u001b[0m, in \u001b[0;36mTensorOp.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m Tensor\u001b[39m.\u001b[39;49mmake_from_op(\u001b[39mself\u001b[39;49m, args)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:242\u001b[0m, in \u001b[0;36mTensor.make_from_op\u001b[0;34m(op, inputs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tensor\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    241\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m--> 242\u001b[0m     tensor\u001b[39m.\u001b[39;49mrealize_cached_data()\n\u001b[1;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:100\u001b[0m, in \u001b[0;36mValue.realize_cached_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n\u001b[1;32m     99\u001b[0m \u001b[39m# note: data implicitly calls realized cached data\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    101\u001b[0m     \u001b[39m*\u001b[39;49m[x\u001b[39m.\u001b[39;49mrealize_cached_data() \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs]\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/ops.py:320\u001b[0m, in \u001b[0;36mMatMul.compute\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, a, b):\n\u001b[1;32m    319\u001b[0m     \u001b[39m### BEGIN YOUR SOLUTION\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mreturn\u001b[39;00m a \u001b[39m@\u001b[39;49m b\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/backend_ndarray/ndarray.py:577\u001b[0m, in \u001b[0;36mNDArray.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    571\u001b[0m         out\u001b[39m.\u001b[39mpermute((\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m    572\u001b[0m         \u001b[39m.\u001b[39mcompact()\n\u001b[1;32m    573\u001b[0m         \u001b[39m.\u001b[39mreshape((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], other\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    574\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     out \u001b[39m=\u001b[39m NDArray\u001b[39m.\u001b[39;49mmake((m, p), device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    578\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mmatmul(\n\u001b[1;32m    579\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompact()\u001b[39m.\u001b[39m_handle, other\u001b[39m.\u001b[39mcompact()\u001b[39m.\u001b[39m_handle, out\u001b[39m.\u001b[39m_handle, m, n, p\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/backend_ndarray/ndarray.py:145\u001b[0m, in \u001b[0;36mNDArray.make\u001b[0;34m(shape, strides, device, handle, offset)\u001b[0m\n\u001b[1;32m    143\u001b[0m array\u001b[39m.\u001b[39m_device \u001b[39m=\u001b[39m device \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m default_device()\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     array\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39;49mArray(prod(shape))\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     array\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mMemoryError\u001b[0m: std::bad_alloc"
     ]
    }
   ],
   "source": [
    "tests.debug.run_needle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('codeserver_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "aca522a4f3a95a8cc19c0c49aa2b52717208ab4d9caac282bf163cf809ab5536"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
