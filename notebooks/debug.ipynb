{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1426.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install --quiet -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "_ = dotenv.load_dotenv(dotenv_path=\"../conf/dev.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import needle as ndl\n",
    "import needle.nn as nn\n",
    "\n",
    "import needle.nn as nn\n",
    "import needle.ops as ops\n",
    "\n",
    "from needle.autograd import Tensor\n",
    "from needle import backend_ndarray as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apps.etl\n",
    "import apps.data\n",
    "import apps.utils.aws\n",
    "import apps.utils.common\n",
    "import apps.models\n",
    "\n",
    "## Hot code reloading, useful during dev:\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport apps.etl\n",
    "%aimport apps.data\n",
    "%aimport apps.models\n",
    "%aimport apps.utils.common\n",
    "%aimport apps.utils.aws.s3\n",
    "%aimport apps.utils.aws.athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"notebooks.debug\")\n",
    "apps.utils.common.setup_logging(config_file=\"../conf/logging.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apps.etl.init_raw_athena_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_days=['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"
     ]
    }
   ],
   "source": [
    "raw_days = sorted([p[0] for p in apps.utils.aws.athena.get_partitions(\"criteo_raw\").values()])\n",
    "print(f\"{raw_days=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apps.utils.aws.athena.run_query(\"select * from criteo_raw where day = '00' limit 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = apps.data.read_s3_dataset(\n",
    "    s3_prefix=\"anatoly/datasets/criteo-terabyte-click-log\", \n",
    "    s3_path=\"preprocessed/joined\",\n",
    "    day_from = 0,\n",
    "    day_to = 0,\n",
    "    batch_size = 1024,\n",
    "    limit_batches = 100,\n",
    "    as_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pbar = tqdm.tqdm(desc=\"reading data\", total=len(dataset_iter))\n",
    "# for batch_id, (X_dense, X_sparse, Y) in enumerate(dataset_iter, start=1):\n",
    "#     pbar.update(n=X_dense.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ndl.cpu()\n",
    "dense_layer_sizes = [512, 256, 64]\n",
    "# interaction_layer_sizes = [512,512,256,1]\n",
    "lr = 0.1 ## also try 4.0, 15.0\n",
    "weight_decay = 0.0\n",
    "model = apps.models.DLRM(\n",
    "    dense_in_features = len(apps.etl.DENSE_COLUMNS),\n",
    "    dense_layer_sizes=[512,256,64],\n",
    "    device=device\n",
    ")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerically unstable version:\n",
    "class BinaryCrossEntropyLoss(nn.Module):\n",
    "    def forward(self, input: Tensor, target: Tensor):\n",
    "        x = input\n",
    "        z = target\n",
    "        size = nd.prod(x.shape)\n",
    "        res = nn.ops.summation(x - x * z + ops.log(1 + nn.ops.exp(-x)))\n",
    "        return nn.ops.divide_scalar(res, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.triu_indices(14, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "          4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  7,  7,\n",
       "          7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9, 10, 10, 10, 11, 11,\n",
       "         12],\n",
       "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  2,  3,  4,  5,  6,\n",
       "          7,  8,  9, 10, 11, 12, 13,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
       "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  5,  6,  7,  8,  9, 10, 11, 12,\n",
       "         13,  6,  7,  8,  9, 10, 11, 12, 13,  7,  8,  9, 10, 11, 12, 13,  8,  9,\n",
       "         10, 11, 12, 13,  9, 10, 11, 12, 13, 10, 11, 12, 13, 11, 12, 13, 12, 13,\n",
       "         13]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.triu_indices(14, 14, offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "# output = torch.full([10, 64], 1.5)  # A prediction (logit)\n",
    "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "# loss_fn(output, target)  # -log(sigmoid(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = Tensor(output.numpy())\n",
    "# target = Tensor(target.numpy())\n",
    "# loss_fn = BinaryCrossEntropyLoss()\n",
    "# loss_fn(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.SoftmaxLoss()\n",
    "loss_fn = BinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ndl.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data:   0%|          | 1024/195871983 [00:18<998:40:20, 54.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:23:18,294 - notebooks.debug - DEBUG - TRAIN on batch_id=1 of size 1024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "AssertionError",
     "evalue": "operation needs two equal-sized arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000032vscode-remote?line=15'>16</a>\u001b[0m opt\u001b[39m.\u001b[39mreset_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000032vscode-remote?line=16'>17</a>\u001b[0m out \u001b[39m=\u001b[39m model(X_dense)\n\u001b[0;32m---> <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000032vscode-remote?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(out, Y)\n\u001b[1;32m     <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000032vscode-remote?line=18'>19</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000032vscode-remote?line=19'>20</a>\u001b[0m opt\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/nn.py:75\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb Cell 15'\u001b[0m in \u001b[0;36mBinaryCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000037vscode-remote?line=4'>5</a>\u001b[0m z \u001b[39m=\u001b[39m target\n\u001b[1;32m      <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000037vscode-remote?line=5'>6</a>\u001b[0m size \u001b[39m=\u001b[39m nd\u001b[39m.\u001b[39mprod(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000037vscode-remote?line=6'>7</a>\u001b[0m res \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39msummation(x \u001b[39m-\u001b[39m x \u001b[39m*\u001b[39;49m z \u001b[39m+\u001b[39m ops\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m nn\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mx)))\n\u001b[1;32m      <a href='vscode-notebook-cell://anatoly-dev-ray-test.notebook.us-east-1.sagemaker.aws/home/ec2-user/SageMaker/code/dlsyscourse-homework/final/notebooks/debug.ipynb#ch0000037vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mdivide_scalar(res, size)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:312\u001b[0m, in \u001b[0;36mTensor.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__mul__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Tensor):\n\u001b[0;32m--> 312\u001b[0m         \u001b[39mreturn\u001b[39;00m needle\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mEWiseMul()(\u001b[39mself\u001b[39;49m, other)\n\u001b[1;32m    313\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m         \u001b[39mreturn\u001b[39;00m needle\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mMulScalar(other)(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:73\u001b[0m, in \u001b[0;36mTensorOp.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m Tensor\u001b[39m.\u001b[39;49mmake_from_op(\u001b[39mself\u001b[39;49m, args)\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:242\u001b[0m, in \u001b[0;36mTensor.make_from_op\u001b[0;34m(op, inputs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tensor\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    241\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m--> 242\u001b[0m     tensor\u001b[39m.\u001b[39;49mrealize_cached_data()\n\u001b[1;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/autograd.py:100\u001b[0m, in \u001b[0;36mValue.realize_cached_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n\u001b[1;32m     99\u001b[0m \u001b[39m# note: data implicitly calls realized cached data\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    101\u001b[0m     \u001b[39m*\u001b[39;49m[x\u001b[39m.\u001b[39;49mrealize_cached_data() \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs]\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/ops.py:112\u001b[0m, in \u001b[0;36mEWiseMul.compute\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, a: NDArray, b: NDArray):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m a \u001b[39m*\u001b[39;49m b\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/backend_ndarray/ndarray.py:471\u001b[0m, in \u001b[0;36mNDArray.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__mul__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 471\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mewise_or_scalar(\n\u001b[1;32m    472\u001b[0m         other, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39;49mewise_mul, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39;49mscalar_mul\n\u001b[1;32m    473\u001b[0m     )\n",
      "File \u001b[0;32m~/SageMaker/code/dlsyscourse-homework/final/python/needle/backend_ndarray/ndarray.py:451\u001b[0m, in \u001b[0;36mNDArray.ewise_or_scalar\u001b[0;34m(self, other, ewise_func, scalar_func)\u001b[0m\n\u001b[1;32m    449\u001b[0m out \u001b[39m=\u001b[39m NDArray\u001b[39m.\u001b[39mmake(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, NDArray):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39moperation needs two equal-sized arrays\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m     ewise_func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompact()\u001b[39m.\u001b[39m_handle, other\u001b[39m.\u001b[39mcompact()\u001b[39m.\u001b[39m_handle, out\u001b[39m.\u001b[39m_handle)\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: operation needs two equal-sized arrays"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "total_errors = 0\n",
    "total_batches = 0\n",
    "total_examples = 0\n",
    "\n",
    "pbar = tqdm.tqdm(desc=\"reading data\", total=len(dataset_iter))\n",
    "for batch_id, (X_dense, X_sparse, Y) in enumerate(dataset_iter, start=1):\n",
    "    pbar.update(n=X_dense.shape[0])\n",
    "    batch_size = Y.shape[0]\n",
    "    logger.debug(f\"TRAIN on {batch_id=} of size {batch_size}...\")\n",
    "    X_dense = np.log(X_dense + 3)\n",
    "    X_dense = Tensor(X_dense, device=device, requires_grad=False)\n",
    "    X_sparse = Tensor(X_sparse, device=device, requires_grad=False)\n",
    "    Y = Y.reshape(1, Y.shape[0])\n",
    "    Y = Tensor(Y, device=device, requires_grad=False)\n",
    "\n",
    "    opt.reset_grad()\n",
    "    out = model(X_dense)\n",
    "    loss = loss_fn(out, Y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    y_prob = out.numpy()\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    errors = np.not_equal(y_pred, Y.numpy()).sum()\n",
    "\n",
    "    cur_loss = loss.numpy()[0]\n",
    "    total_loss += cur_loss\n",
    "    total_errors += errors\n",
    "    total_batches += 1\n",
    "    total_examples += batch_size\n",
    "\n",
    "    avg_loss = (total_loss / total_batches)\n",
    "    avg_error_rate = total_errors / total_examples\n",
    "\n",
    "    logger.debug(f\"TRAIN on {batch_id=} of size {batch_size}: done ({cur_loss=}, {total_loss=}, {total_batches=}, {avg_loss=:0.4f}, {avg_error_rate=:0.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('codeserver_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca522a4f3a95a8cc19c0c49aa2b52717208ab4d9caac282bf163cf809ab5536"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
